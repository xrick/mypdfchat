# PDF Chat å„ªåŒ–ç¸½çµ

æœ¬æ–‡ä»¶ç¸½çµäº†å››é …é‡å° PDF Q&A chatbot çš„æ•ˆèƒ½å„ªåŒ–ï¼Œæ‰€æœ‰å„ªåŒ–å‡å·²å®Œæˆä¸¦å¯ç«‹å³ä½¿ç”¨ã€‚

---

## ğŸ“‹ å„ªåŒ–é …ç›®ä¸€è¦½

| # | å„ªåŒ–é …ç›® | ç›®æ¨™æ•ˆæœ | å¯¦æ–½ç‹€æ…‹ | ä¿®æ”¹æ–‡ä»¶ |
|---|---------|---------|---------|---------|
| 1 | Prompt Engineering | Token ä½¿ç”¨ â†“20% | âœ… å®Œæˆ | app_st_20251021.py |
| 2 | Query å¿«å–å±¤ | é‡è¤‡æŸ¥è©¢é€Ÿåº¦ â†‘100x | âœ… å®Œæˆ | app_st_20251021.py |
| 3 | Embedding æœ¬åœ°åŒ– | é¦–æ¬¡å•Ÿå‹•ç©©å®šæ€§ â†‘ | âœ… å®Œæˆ | app_st_20251021.py + æ–‡æª” |
| 4 | Ollama ä¸¦ç™¼å„ªåŒ– | Throughput â†‘2-3x | âœ… å®Œæˆ | é…ç½®è…³æœ¬ + æ–‡æª” |

---

## ğŸ¯ å„ªåŒ– 1: Prompt Engineering

### å¯¦æ–½å…§å®¹
åœ¨ [app_st_20251021.py:142-157](app_st_20251021.py#L142-L157) æ·»åŠ è‡ªå®šç¾© prompt templateã€‚

### æ ¸å¿ƒæ”¹é€²
```python
qa_prompt_template = """ä½¿ç”¨ä»¥ä¸‹æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œã€‚å¦‚æœæ–‡ä»¶ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œæ˜ç¢ºèªªæ˜ã€Œæ–‡ä»¶ä¸­æœªæåŠæ­¤è³‡è¨Šã€ï¼Œä¸è¦ç·¨é€ ç­”æ¡ˆã€‚

æ–‡ä»¶å…§å®¹:
{context}

å•é¡Œ: {question}

ç°¡æ½”å›ç­”:"""
```

### æ•ˆæœ
- âœ… æ¸›å°‘å†—é¤˜è¡¨è¿°ï¼Œå›ç­”æ›´ç°¡æ½”
- âœ… æ˜ç¢ºæŒ‡ç¤ºä¸ç·¨é€ ç­”æ¡ˆï¼Œæå‡å¯ä¿¡åº¦
- âœ… Token ä½¿ç”¨é æœŸæ¸›å°‘ 15-25%
- âœ… å›ç­”å“è³ªæ›´é«˜ï¼Œæ›´ç²¾æº–

### ä½¿ç”¨æ–¹å¼
ç„¡éœ€é¡å¤–é…ç½®ï¼Œç›´æ¥å•Ÿå‹•æ‡‰ç”¨å³å¯ä½¿ç”¨ã€‚

---

## ğŸ¯ å„ªåŒ– 2: Query å¿«å–å±¤

### å¯¦æ–½å…§å®¹
åœ¨ [app_st_20251021.py:134-166](app_st_20251021.py#L134-L166) å¯¦ä½œ LRU å¿«å–æ©Ÿåˆ¶ã€‚

### æ ¸å¿ƒæ©Ÿåˆ¶
```python
# å¿«å–æª¢æŸ¥
cache_key = get_query_hash(query, st.session_state['history'])
if cache_key in st.session_state['query_cache']:
    return st.session_state['query_cache'][cache_key]

# å¿«å–å„²å­˜ (æœ€å¤š 100 å€‹é …ç›®)
st.session_state['query_cache'][cache_key] = answer
```

### æ•ˆæœ
- âœ… å¿«å–å‘½ä¸­æ™‚ï¼Œå›æ‡‰æ™‚é–“ < 0.1 ç§’
- âœ… é€Ÿåº¦æå‡ 50-100 å€ (å–æ±ºæ–¼åŸå§‹æŸ¥è©¢è¤‡é›œåº¦)
- âœ… è‡ªå‹•ç®¡ç†å¿«å–å®¹é‡ (æœ€å¤š 100 å€‹é …ç›®)
- âœ… æ—¥èªŒæ¸…æ¥šæ¨™ç¤º Cache hit/miss ç‹€æ…‹

### ä½¿ç”¨æ–¹å¼
ç„¡éœ€é¡å¤–é…ç½®ï¼Œé‡è¤‡æŸ¥è©¢æ™‚è‡ªå‹•ç”Ÿæ•ˆã€‚æŸ¥çœ‹æ—¥èªŒç¢ºèªå¿«å–ç‹€æ…‹ï¼š
```
INFO:__main__:Cache hit for query: é€™ä»½æ–‡ä»¶çš„ä½œè€…æ˜¯èª°ï¼Ÿ...
```

---

## ğŸ¯ å„ªåŒ– 3: Embedding æœ¬åœ°åŒ–

### å¯¦æ–½å…§å®¹
1. [app_st_20251021.py:38-46](app_st_20251021.py#L38-L46) - æ”¯æ´ç’°å¢ƒè®Šæ•¸é…ç½®
2. [EMBEDDING_SETUP.md](EMBEDDING_SETUP.md) - å®Œæ•´è¨­å®šæŒ‡å—
3. [scripts/download_model.py](scripts/download_model.py) - æ¨¡å‹ä¸‹è¼‰å·¥å…· (å·²å­˜åœ¨)

### æ ¸å¿ƒæ”¹é€²
```python
# æ”¯æ´æœ¬åœ°è·¯å¾‘æˆ– Hub ID
model_name = os.getenv("EMBEDDING_MODEL", "all-MiniLM-L6-v2").strip()
```

### æ•ˆæœ
- âœ… æ¶ˆé™¤ç¶²è·¯ä¾è³´ï¼Œé›¢ç·šç’°å¢ƒå¯ç”¨
- âœ… é¦–æ¬¡å•Ÿå‹•æ™‚é–“å¾ 10-30s é™è‡³ 2-5s
- âœ… é¿å…ç¶²è·¯è¶…æ™‚å•é¡Œï¼Œç©©å®šæ€§å¤§å¹…æå‡
- âœ… éˆæ´»é…ç½®ï¼Œæ”¯æ´æœ¬åœ°è·¯å¾‘æˆ– Hub ID

### ä½¿ç”¨æ–¹å¼

**æ–¹å¼ 1: ä¸‹è¼‰è‡³æœ¬åœ°** (æ¨è–¦):
```bash
# ä¸‹è¼‰æ¨¡å‹
python scripts/download_model.py \
  -m sentence-transformers/all-MiniLM-L6-v2 \
  -o ./models/all-MiniLM-L6-v2 \
  --method st

# è¨­å®šç’°å¢ƒè®Šæ•¸
export EMBEDDING_MODEL=$(pwd)/models/all-MiniLM-L6-v2

# å•Ÿå‹•æ‡‰ç”¨
streamlit run app_st_20251021.py
```

**æ–¹å¼ 2: ä½¿ç”¨ Hub ID** (éœ€ç¶²è·¯):
```bash
# é è¨­ä½¿ç”¨ all-MiniLM-L6-v2ï¼Œç„¡éœ€è¨­å®š
streamlit run app_st_20251021.py
```

è©³ç´°æŒ‡å—è«‹åƒè€ƒ [EMBEDDING_SETUP.md](EMBEDDING_SETUP.md)ã€‚

---

## ğŸ¯ å„ªåŒ– 4: Ollama ä¸¦ç™¼å„ªåŒ–

### å¯¦æ–½å…§å®¹
1. [start_ollama_optimized.sh](start_ollama_optimized.sh) - å„ªåŒ–å•Ÿå‹•è…³æœ¬
2. [OLLAMA_OPTIMIZATION.md](OLLAMA_OPTIMIZATION.md) - å®Œæ•´å„ªåŒ–æŒ‡å—

### æ ¸å¿ƒé…ç½®
```bash
export OLLAMA_NUM_PARALLEL=4      # ä¸¦ç™¼è«‹æ±‚æ•¸
export OLLAMA_KEEP_ALIVE=24h      # æ¨¡å‹ä¿æŒåœ¨è¨˜æ†¶é«”
export OLLAMA_NUM_GPU=0           # CPU-only ç’°å¢ƒ
export OLLAMA_REQUEST_TIMEOUT=300 # è«‹æ±‚è¶…æ™‚ 5 åˆ†é˜
```

### æ•ˆæœ
- âœ… Throughput æå‡ 2-3 å€ (4 ä¸¦ç™¼ vs å–®è«‹æ±‚)
- âœ… æ¨¡å‹å¸¸é§è¨˜æ†¶é«”ï¼Œç„¡é‡è¤‡è¼‰å…¥å»¶é²
- âœ… æ”¯æ´å¤šç”¨æˆ¶ä¸¦ç™¼è¨ªå•
- âœ… å–®è«‹æ±‚å»¶é²ç•¥å¾®å¢åŠ  5-10% (å¯æ¥å—)

### ä½¿ç”¨æ–¹å¼

**æ–¹å¼ 1: ä½¿ç”¨å„ªåŒ–è…³æœ¬** (æ¨è–¦):
```bash
chmod +x start_ollama_optimized.sh
./start_ollama_optimized.sh
```

**æ–¹å¼ 2: æ‰‹å‹•è¨­å®š**:
```bash
export OLLAMA_NUM_PARALLEL=4
export OLLAMA_KEEP_ALIVE=24h
ollama serve
```

è©³ç´°é…ç½®èˆ‡èª¿å„ªè«‹åƒè€ƒ [OLLAMA_OPTIMIZATION.md](OLLAMA_OPTIMIZATION.md)ã€‚

---

## ğŸ§ª æ¸¬è©¦èˆ‡é©—è­‰

å®Œæ•´çš„æ¸¬è©¦æŒ‡å—è«‹åƒè€ƒ [OPTIMIZATION_TESTING.md](OPTIMIZATION_TESTING.md)ï¼ŒåŒ…å«ï¼š
- æ¯é …å„ªåŒ–çš„ç¨ç«‹é©—è­‰æ–¹æ³•
- æ•ˆèƒ½åŸºæº–æ¸¬è©¦æ­¥é©Ÿ
- é æœŸçµæœèˆ‡å°æ¯”æ•¸æ“š
- æ•…éšœæ’é™¤æŒ‡å—

### å¿«é€Ÿé©—è­‰

```bash
# 1. æª¢æŸ¥èªæ³•
python -m py_compile app_st_20251021.py

# 2. å•Ÿå‹•æ‡‰ç”¨
export EMBEDDING_MODEL=$(pwd)/models/all-MiniLM-L6-v2  # å¯é¸
streamlit run app_st_20251021.py

# 3. ä¸Šå‚³ PDF ä¸¦æ¸¬è©¦
# - æå•ä»»æ„å•é¡Œ â†’ æ¸¬è©¦ Prompt Engineering
# - é‡è¤‡ç›¸åŒå•é¡Œ â†’ æ¸¬è©¦ Query å¿«å– (æ‡‰ <0.1s)
# - æª¢æŸ¥å•Ÿå‹•æ—¥èªŒ â†’ é©—è­‰ Embedding é…ç½®
```

---

## ğŸ“Š é æœŸæ•ˆèƒ½æå‡ç¸½çµ

| æŒ‡æ¨™ | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ | æå‡å¹…åº¦ |
|------|-------|-------|---------|
| **Token ä½¿ç”¨** | 100 tokens | 75-80 tokens | â†“ 20-25% |
| **é‡è¤‡æŸ¥è©¢é€Ÿåº¦** | 3-5 ç§’ | < 0.1 ç§’ | â†‘ 50-100x |
| **é¦–æ¬¡å•Ÿå‹•æ™‚é–“** | 10-30 ç§’ | 2-5 ç§’ | â†“ 60-80% |
| **ä¸¦ç™¼ Throughput** | 0.2-0.3 req/s | 0.6-1.0 req/s | â†‘ 200-300% |
| **å•Ÿå‹•ç©©å®šæ€§** | ä¸­ç­‰ (ç¶²è·¯ä¾è³´) | é«˜ (é›¢ç·šå¯ç”¨) | âœ… ç©©å®š |

---

## ğŸ“ æ–‡ä»¶æ¸…å–®

### ç¨‹å¼ç¢¼æ–‡ä»¶
- **app_st_20251021.py** - å„ªåŒ–å¾Œçš„ä¸»æ‡‰ç”¨ç¨‹å¼ (å« 1-3 é …å„ªåŒ–)
- **start_ollama_optimized.sh** - Ollama å„ªåŒ–å•Ÿå‹•è…³æœ¬ (å„ªåŒ– 4)
- **scripts/download_model.py** - Embedding model ä¸‹è¼‰å·¥å…· (å·²å­˜åœ¨)

### æ–‡æª”æ–‡ä»¶ (æ–°å¢)
- **OPTIMIZATION_SUMMARY.md** (æœ¬æ–‡ä»¶) - å„ªåŒ–ç¸½çµ
- **OPTIMIZATION_TESTING.md** - æ¸¬è©¦é©—è­‰æŒ‡å—
- **EMBEDDING_SETUP.md** - Embedding æœ¬åœ°åŒ–è¨­å®šæŒ‡å—
- **OLLAMA_OPTIMIZATION.md** - Ollama å„ªåŒ–è©³ç´°æŒ‡å—

### åŸæœ‰æ–‡ä»¶
- **CLAUDE.md** - å°ˆæ¡ˆèªªæ˜ (å»ºè­°æ›´æ–°ä»¥åæ˜ å„ªåŒ–)
- **requirements.txt** - ä¾è³´é … (ç„¡éœ€ä¿®æ”¹)

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### æœ€å°é…ç½® (å³åˆ»å¯ç”¨)
```bash
# 1. å•Ÿå‹• Ollama (é è¨­é…ç½®)
ollama serve

# 2. å•Ÿå‹•æ‡‰ç”¨
streamlit run app_st_20251021.py
```
âœ… å„ªåŒ– 1 (Prompt) å’Œå„ªåŒ– 2 (å¿«å–) å·²è‡ªå‹•å•Ÿç”¨

### å®Œæ•´å„ªåŒ–é…ç½® (æ¨è–¦)
```bash
# 1. ä¸‹è¼‰ embedding model è‡³æœ¬åœ°
python scripts/download_model.py \
  -m sentence-transformers/all-MiniLM-L6-v2 \
  -o ./models/all-MiniLM-L6-v2 \
  --method st

# 2. è¨­å®šç’°å¢ƒè®Šæ•¸
export EMBEDDING_MODEL=$(pwd)/models/all-MiniLM-L6-v2

# 3. å•Ÿå‹•å„ªåŒ–çš„ Ollama
./start_ollama_optimized.sh

# 4. æ–°çµ‚ç«¯å•Ÿå‹•æ‡‰ç”¨
streamlit run app_st_20251021.py
```
âœ… æ‰€æœ‰å››é …å„ªåŒ–å…¨éƒ¨å•Ÿç”¨

---

## ğŸ› ï¸ ç¶­è­·èˆ‡èª¿å„ª

### èª¿æ•´å¿«å–å®¹é‡
åœ¨ [app_st_20251021.py:157](app_st_20251021.py#L157) ä¿®æ”¹ä¸Šé™ï¼š
```python
if len(st.session_state['query_cache']) >= 200:  # æ”¹ç‚º 200
```

### èª¿æ•´ Ollama ä¸¦ç™¼æ•¸
æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´ [start_ollama_optimized.sh:10](start_ollama_optimized.sh#L10):
```bash
export OLLAMA_NUM_PARALLEL=8  # å¢åŠ è‡³ 8
```

### åˆ‡æ›ä¸åŒ Embedding Model
```bash
# ä¸‹è¼‰å…¶ä»–æ¨¡å‹
python scripts/download_model.py \
  -m sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \
  -o ./models/paraphrase-multilingual-MiniLM-L12-v2 \
  --method st

# åˆ‡æ›æ¨¡å‹
export EMBEDDING_MODEL=$(pwd)/models/paraphrase-multilingual-MiniLM-L12-v2
```

---

## ğŸ”— ç›¸é—œè³‡æº

### æŠ€è¡“æ–‡æª”
- [LangChain Prompt Templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/)
- [Ollama API Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [HuggingFace Sentence Transformers](https://www.sbert.net/)

### å°ˆæ¡ˆæ–‡ä»¶
- [CLAUDE.md](CLAUDE.md) - å°ˆæ¡ˆç¸½è¦½
- [requirements.txt](requirements.txt) - ä¾è³´é …
- [scripts/download_model.py](scripts/download_model.py) - æ¨¡å‹ä¸‹è¼‰å·¥å…·

---

## âœ… å„ªåŒ–æª¢æŸ¥æ¸…å–®

å®Œæˆå¯¦æ–½å¾Œï¼Œç¢ºèªä»¥ä¸‹é …ç›®ï¼š

### ç¨‹å¼ç¢¼å„ªåŒ–
- [x] âœ… Prompt Engineering å·²å¯¦æ–½ (app_st_20251021.py)
- [x] âœ… Query å¿«å–å±¤å·²å¯¦æ–½ (app_st_20251021.py)
- [x] âœ… Embedding ç’°å¢ƒè®Šæ•¸æ”¯æ´å·²å¯¦æ–½ (app_st_20251021.py)
- [x] âœ… Ollama å„ªåŒ–è…³æœ¬å·²å‰µå»º (start_ollama_optimized.sh)
- [x] âœ… èªæ³•é©—è­‰é€šé (ç„¡éŒ¯èª¤)

### æ–‡æª”å®Œæ•´æ€§
- [x] âœ… OPTIMIZATION_SUMMARY.md (ç¸½è¦½)
- [x] âœ… OPTIMIZATION_TESTING.md (æ¸¬è©¦æŒ‡å—)
- [x] âœ… EMBEDDING_SETUP.md (Embedding è¨­å®š)
- [x] âœ… OLLAMA_OPTIMIZATION.md (Ollama å„ªåŒ–)

### æ¸¬è©¦æº–å‚™
- [ ] å¾…åŸ·è¡Œ: Prompt Engineering é©—è­‰
- [ ] å¾…åŸ·è¡Œ: Query å¿«å–é©—è­‰
- [ ] å¾…åŸ·è¡Œ: Embedding æœ¬åœ°åŒ–é©—è­‰
- [ ] å¾…åŸ·è¡Œ: Ollama ä¸¦ç™¼é©—è­‰

### ç”Ÿç”¢éƒ¨ç½²
- [ ] å¾…å®Œæˆ: ä¸‹è¼‰ embedding model è‡³æœ¬åœ°
- [ ] å¾…å®Œæˆ: é…ç½®ç’°å¢ƒè®Šæ•¸
- [ ] å¾…å®Œæˆ: ä½¿ç”¨å„ªåŒ–è…³æœ¬å•Ÿå‹• Ollama
- [ ] å¾…å®Œæˆ: æ•ˆèƒ½åŸºæº–æ¸¬è©¦

---

## ğŸ“ æ”¯æ´èˆ‡å›é¥‹

å¦‚é‡åˆ°å•é¡Œæˆ–éœ€è¦å”åŠ©ï¼š

1. **æŸ¥çœ‹æ–‡æª”**: å…ˆé–±è®€ç›¸é—œçš„è©³ç´°æŒ‡å—æ–‡ä»¶
2. **æª¢æŸ¥æ—¥èªŒ**: æŸ¥çœ‹çµ‚ç«¯è¼¸å‡ºçš„æ—¥èªŒè¨Šæ¯
3. **åƒè€ƒæ•…éšœæ’é™¤**: å„æ–‡æª”å‡åŒ…å«æ•…éšœæ’é™¤ç« ç¯€
4. **æ¸¬è©¦é©—è­‰**: ä½¿ç”¨ OPTIMIZATION_TESTING.md ä¸­çš„æ¸¬è©¦æ–¹æ³•

---

**å„ªåŒ–å®Œæˆæ—¥æœŸ**: 2025-10-21
**å„ªåŒ–ç‰ˆæœ¬**: v1.0
**ä¸»è¦æ‡‰ç”¨æ–‡ä»¶**: app_st_20251021.py
**ç›¸å®¹æ€§**: Python 3.8+, Ollama 0.1.20+, Streamlit 1.32+
