# DocAI RAG Application - Quick Start Guide

## ç³»çµ±ç¾æ³ âœ…

å·²å°±ç·’ï¼š
- âœ… Code implementation å®Œæˆ
- âœ… Ollama æ­£åœ¨é‹è¡Œ (9 models å¯ç”¨)
- âœ… Redis æ­£åœ¨é‹è¡Œ
- âœ… `.env` å·²é…ç½®

éœ€è¦è™•ç†ï¼š
- âŒ Python dependencies (PyPDF2, pymongo ç­‰)
- âŒ MongoDB æœå‹™æœªå•Ÿå‹•

---

## Step-by-Step å•Ÿå‹•æŒ‡å—

### Step 1: å®‰è£ Python Dependencies (1-2 åˆ†é˜)

```bash
# æ–¹å¼ A: åªå®‰è£ç¼ºå¤±çš„æ ¸å¿ƒå¥—ä»¶ (å¿«é€Ÿ)
pip install PyPDF2 pymongo

# æ–¹å¼ B: å®Œæ•´å®‰è£ (æ¨è–¦ï¼Œ5-10 åˆ†é˜)
pip install -r requirements.txt
```

**é æœŸè¼¸å‡º**ï¼š
```
Successfully installed PyPDF2-3.0.1 pymongo-4.6.1 ...
```

---

### Step 2: å•Ÿå‹• MongoDB (30 ç§’)

```bash
# æ–¹å¼ A: Docker (æ¨è–¦)
docker run -d -p 27017:27017 --name mongodb mongo:latest

# æ–¹å¼ B: ç³»çµ±æœå‹™
sudo systemctl start mongodb

# é©—è­‰
nc -zv localhost 27017
# é æœŸè¼¸å‡º: Connection to localhost 27017 port [tcp/*] succeeded!
```

---

### Step 3: å•Ÿå‹• DocAI Application

```bash
# å¾å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œ
python main.py
```

**é æœŸè¼¸å‡º**ï¼š
```
INFO:     ğŸš€ Starting DocAI v1.0.0
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

---

### Step 4: æ¸¬è©¦ç³»çµ± (1 åˆ†é˜)

#### 4.1 å¥åº·æª¢æŸ¥
```bash
curl http://localhost:8000/health
```
é æœŸå›æ‡‰: `{"status":"ok"}`

#### 4.2 æ‰“é–‹å‰ç«¯
ç€è¦½å™¨è¨ªå•: http://localhost:8000

é æœŸçœ‹åˆ°: DocAI ä¸Šå‚³ä»‹é¢

#### 4.3 æ¸¬è©¦ PDF ä¸Šå‚³
```bash
# æº–å‚™æ¸¬è©¦ PDF (æˆ–ä½¿ç”¨ä½ è‡ªå·±çš„ PDF)
curl -X POST http://localhost:8000/api/v1/upload \
  -F "file=@test.pdf"
```

é æœŸå›æ‡‰:
```json
{
  "file_id": "file_abc123...",
  "filename": "test.pdf",
  "status": "success"
}
```

#### 4.4 æ¸¬è©¦ Chat (SSE Streaming)
```bash
curl -X POST http://localhost:8000/api/v1/chat/stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "é€™ä»½æ–‡ä»¶åœ¨è¬›ä»€éº¼ï¼Ÿ",
    "file_ids": ["file_abc123..."],
    "session_id": "test_session"
  }'
```

é æœŸè¼¸å‡º: Server-Sent Events stream with markdown tokens

---

## Troubleshooting å¿«é€Ÿåƒè€ƒ

### å•é¡Œ 1: ImportError: No module named 'PyPDF2'
**è§£æ±º**: `pip install PyPDF2`

### å•é¡Œ 2: MongoDB connection failed
**æª¢æŸ¥**: `nc -zv localhost 27017`
**è§£æ±º**: `docker run -d -p 27017:27017 mongo:latest`

### å•é¡Œ 3: Ollama model not found
**æª¢æŸ¥å¯ç”¨ models**: `curl http://localhost:11434/api/tags`
**ä¿®æ”¹ .env**: `LLM_MODEL_NAME=deepseek-r1:7b` (ä½ æœ‰é€™å€‹ model)

### å•é¡Œ 4: Port 8000 already in use
**è§£æ±º**: ä¿®æ”¹ `.env` ä¸­çš„ `PORT=8001`

---

## ç³»çµ±æ¶æ§‹é€Ÿè¦½

```
ç”¨æˆ¶ä¸Šå‚³ PDF
    â†“
[upload.py] â†’ InputDataHandleService
    â†“         (extract â†’ chunk â†’ hierarchical indexing)
    â†“
VectorStore (FAISS/Milvus)
    â†“
ç”¨æˆ¶æå•
    â†“
[chat.py] â†’ 5-Phase RAG Pipeline
    â”œâ”€ Phase 1: Query Understanding (Question Expansion)
    â”œâ”€ Phase 2: Parallel Retrieval (Multi-query)
    â”œâ”€ Phase 3: Context Assembly
    â”œâ”€ Phase 4: Response Generation (OPMP streaming)
    â””â”€ Phase 5: Post Processing (save history)
    â†“
SSE Stream â†’ Frontend OPMP Client â†’ Progressive Markdown Rendering
```

---

## å¯ç”¨çš„ Ollama Models (å·²å®‰è£)

å¾æª¢æŸ¥çµæœï¼Œä½ æœ‰ä»¥ä¸‹ models å¯ç”¨ï¼š

1. **zephyr:7b** â† .env é è¨­ä½¿ç”¨
2. **deepseek-r1:7b** (æ¨è–¦ï¼Œ7.6B åƒæ•¸)
3. **deepseek-r1:latest** (8.2B)
4. **phi4-mini-reasoning:3.8b** (æ¨ç†å¢å¼·)
5. **codellama:7b** (ç¨‹å¼ç¢¼å°ˆç”¨)
6. **deepseek-coder-v2:16b** (å¤§å‹ç¨‹å¼ç¢¼æ¨¡å‹)
7. **gpt-oss:20b** (20B å¤§æ¨¡å‹)

ä¿®æ”¹ `.env` çš„ `LLM_MODEL_NAME` å³å¯åˆ‡æ›ã€‚

---

## ä¸‹ä¸€æ­¥

ç³»çµ±å•Ÿå‹•å¾Œï¼š

1. ä¸Šå‚³æ¸¬è©¦ PDF æ–‡ä»¶
2. æ¸¬è©¦ chat streaming (è§€å¯Ÿ 5 phase progress indicators)
3. æª¢æŸ¥ MongoDB chat history æ˜¯å¦æ­£ç¢ºå„²å­˜
4. è§€å¯Ÿ OPMP progressive rendering æ•ˆæœ

è©³ç´°æ–‡æª”ï¼š
- å®Œæ•´ä¼°ç®—å ±å‘Š: `claudedocs/estimation_report_20251029.md`
- æ¶æ§‹èªªæ˜: `claudedocs/core_logic_service_to_endpoint_chat.md`
- Implementation summary: `claudedocs/implementation_summary_20251029.md`

---

**Last Updated**: 2025-10-29
**Status**: âœ… Ready to run (after Step 1-2)
